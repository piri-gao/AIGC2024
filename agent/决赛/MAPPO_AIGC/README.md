# MAPPO in AIGC Environment
This is a concise Pytorch implementation of MAPPO in AIGC environment.<br />


## How to use my code?
You can dircetly run 'MAPPO_AIGC_main.py' in your own IDE.<br />

## Trainning environments
You can set the 'env_index' in the codes to change the maps in AIGC. Here, we train our code in 10vs10 maps.<br />

## Requirements
python==3.7.9<br />
numpy==1.19.4<br />
pytorch==1.12.0<br />
tensorboard==0.6.0<br />

## Trainning results


## Reference
[1] Yu C, Velu A, Vinitsky E, et al. The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games[J]. arXiv preprint arXiv:2103.01955, 2021.<br />
[2] [Official implementation of MAPPO](https://github.com/marlbenchmark/on-policy)<br />
[3] [EPyMARL](https://github.com/uoe-agents/epymarl)
